{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "\n",
    "import sinusoid_regression_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sinusoid_regression_dataset.SinusoidRegression(32, 5, 666)\n",
    "def net(x):\n",
    "    x = hk.nets.MLP((32, 32, 32, 32, 2))(x)\n",
    "    return jnp.split(x, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/home/yarden/miniconda3/envs/jax-ml/lib/python3.10/site-packages/haiku/_src/base.py:515: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  param = init(shape, dtype)\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "\n",
    "init, apply = hk.without_apply_rng(hk.transform(net))\n",
    "n_particles = 10\n",
    "init = jax.vmap(init, (0, None))\n",
    "apply = jax.vmap(apply, (0, None))\n",
    "seed_sequence = hk.PRNGSequence(666)\n",
    "example = next(dataset.train_set)[0]\n",
    "hyper_prior_particles = init(jnp.asarray(seed_sequence.take(n_particles)), example)\n",
    "hyper_prior = models.ParamsMeanField(hyper_prior_particles)\n",
    "prior_particles = init(jnp.asarray(seed_sequence.take(n_particles)), example)\n",
    "prior = models.ParamsMeanField(hyper_prior_particles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'mlp/~/linear_0' of type <class 'str'> is not a valid JAX type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m opt \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39mflatten(optax\u001b[39m.\u001b[39madam(\u001b[39m2e-3\u001b[39m))\n\u001b[1;32m      5\u001b[0m opt_state \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39minit(prior_particles)\n\u001b[0;32m----> 6\u001b[0m pacoh_nn\u001b[39m.\u001b[39;49mmeta_train(dataset\u001b[39m.\u001b[39;49mtrain_set, apply, hyper_prior, prior, opt, opt_state, \u001b[39m1\u001b[39;49m, \u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/ethz/jax-pacoh-nn/pacoh_nn.py:31\u001b[0m, in \u001b[0;36mmeta_train\u001b[0;34m(data, prediction_fn, hyper_prior, prior, optimizer, opt_state, iterations, n_prior_samples)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n\u001b[1;32m     30\u001b[0m     meta_batch_x, meta_batch_y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(data)\n\u001b[0;32m---> 31\u001b[0m     hyper_posterior, opt_state, loss \u001b[39m=\u001b[39m train_step(\n\u001b[1;32m     32\u001b[0m         meta_batch_x,\n\u001b[1;32m     33\u001b[0m         meta_batch_y,\n\u001b[1;32m     34\u001b[0m         prediction_fn,\n\u001b[1;32m     35\u001b[0m         hyper_prior,\n\u001b[1;32m     36\u001b[0m         hyper_posterior,\n\u001b[1;32m     37\u001b[0m         \u001b[39mnext\u001b[39;49m(keys),\n\u001b[1;32m     38\u001b[0m         n_prior_samples,\n\u001b[1;32m     39\u001b[0m         optimizer,\n\u001b[1;32m     40\u001b[0m         opt_state,\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     43\u001b[0m         \u001b[39mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m~/ethz/jax-pacoh-nn/pacoh_nn.py:73\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(meta_batch_x, meta_batch_y, prediction_fn, hyper_prior, prior, key, n_prior_samples, optimizer, opt_state)\u001b[0m\n\u001b[1;32m     70\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m(mll \u001b[39m+\u001b[39m log_prob_prior)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     71\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n\u001b[0;32m---> 73\u001b[0m loss, grads \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mvalue_and_grad(log_probs)(prior)\n\u001b[1;32m     74\u001b[0m updates, new_opt_state \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mupdate(grads, opt_state)\n\u001b[1;32m     75\u001b[0m new_params \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39mapply_updates(prior\u001b[39m.\u001b[39mparams, updates)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-ml/lib/python3.10/site-packages/jax/_src/api.py:3080\u001b[0m, in \u001b[0;36m_check_arg\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m   3078\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_arg\u001b[39m(arg):\n\u001b[1;32m   3079\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(arg, core\u001b[39m.\u001b[39mTracer) \u001b[39mor\u001b[39;00m _valid_jaxtype(arg)):\n\u001b[0;32m-> 3080\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mArgument \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00marg\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(arg)\u001b[39m}\u001b[39;00m\u001b[39m is not a valid JAX type.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'mlp/~/linear_0' of type <class 'str'> is not a valid JAX type."
     ]
    }
   ],
   "source": [
    "import optax\n",
    "import pacoh_nn\n",
    "\n",
    "opt = optax.flatten(optax.adam(2e-3))\n",
    "opt_state = opt.init(prior_particles)\n",
    "pacoh_nn.meta_train(dataset.train_set, apply, hyper_prior, prior, opt, opt_state, 1, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "895d185bae83ce73d2d93b4a85b26b7788fe0555a81bf0fba8f6e903c7e6a527"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
